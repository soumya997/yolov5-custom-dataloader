{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "# from utils.dataloaders import create_dataloader\n",
    "# from utils.dataloaders import LoadImagesAndLabels\n",
    "# YOLOv5 ðŸš€ by Ultralytics, AGPL-3.0 license\n",
    "\"\"\"\n",
    "Dataloaders and dataset utils\n",
    "\"\"\"\n",
    "\n",
    "import contextlib\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from itertools import repeat\n",
    "from multiprocessing.pool import Pool, ThreadPool\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import numpy as np\n",
    "import psutil\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import yaml\n",
    "from PIL import ExifTags, Image, ImageOps\n",
    "from torch.utils.data import DataLoader, Dataset, dataloader, distributed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.augmentations import (Albumentations, augment_hsv, classify_albumentations, classify_transforms, copy_paste,\n",
    "                                 letterbox, mixup, random_perspective)\n",
    "from utils.general import (DATASETS_DIR, LOGGER, NUM_THREADS, TQDM_BAR_FORMAT, check_dataset, check_requirements,\n",
    "                           check_yaml, clean_str, cv2, is_colab, is_kaggle, segments2boxes, unzip_file, xyn2xy,\n",
    "                           xywh2xyxy, xywhn2xyxy, xyxy2xywhn)\n",
    "from utils.torch_utils import torch_distributed_zero_first\n",
    "\n",
    "# Parameters\n",
    "HELP_URL = 'See https://docs.ultralytics.com/yolov5/tutorials/train_custom_data'\n",
    "IMG_FORMATS = 'bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp', 'pfm'  # include image suffixes\n",
    "VID_FORMATS = 'asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'ts', 'wmv'  # include video suffixes\n",
    "LOCAL_RANK = int(os.getenv('LOCAL_RANK', -1))  # https://pytorch.org/docs/stable/elastic/run.html\n",
    "RANK = int(os.getenv('RANK', -1))\n",
    "PIN_MEMORY = str(os.getenv('PIN_MEMORY', True)).lower() == 'true'  # global pin_memory for dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 path,\n",
    "                 img_size=640,\n",
    "                 batch_size=16,\n",
    "                 augment=False,\n",
    "                 hyp=None,\n",
    "                 rect=False,\n",
    "                 image_weights=False,\n",
    "                 cache_images=False,\n",
    "                 single_cls=False,\n",
    "                 stride=32,\n",
    "                 pad=0.0,\n",
    "                 min_items=0,\n",
    "                 prefix=''):\n",
    "        self.path = path\n",
    "        self.im_files = [os.path.join(self.path, filename) for filename in os.listdir(self.path)]\n",
    "        self.indices = range(len(self.im_files))\n",
    "        self.img_size = img_size\n",
    "        # self.batch_size = batch_size\n",
    "        self.ims = [None] * len(self.im_files)\n",
    "        self.im_hw0 = [None] * len(self.im_files)\n",
    "        self.im_hw = [None] * len(self.im_files)\n",
    "        self.npy_files = []\n",
    "        self.augment = augment\n",
    "        self.shapes = np.array([cv2.imread(img_fn).shape[:2] for img_fn in self.im_files])\n",
    "        self.rect = rect\n",
    "        self.template = cv2.imread('/home/somusan/somusan/soumyadip/interview/lens_assignment/1_3_crop.tif')\n",
    "        self.hyp = hyp\n",
    "        self.albumentations = Albumentations(size=img_size) if augment else None\n",
    "\n",
    "        # Create indices\n",
    "        n = len(self.shapes)  # number of images\n",
    "        bi = np.floor(np.arange(n) / batch_size).astype(int)  # batch index\n",
    "        nb = bi[-1] + 1  # number of batches\n",
    "        self.batch = bi  # batch index of image\n",
    "        self.n = n\n",
    "        self.indices = range(n)\n",
    "\n",
    "        #labels temp\n",
    "        dummy_labels = np.random.rand(1, 5)\n",
    "        dummy_labels[:, 0] = [0.0]\n",
    "        self.labels = [dummy_labels] * n\n",
    "\n",
    "\n",
    "        # Rectangular Training\n",
    "        if self.rect:\n",
    "            # Sort by aspect ratio\n",
    "            s = self.shapes  # wh\n",
    "            ar = s[:, 1] / s[:, 0]  # aspect ratio\n",
    "            irect = ar.argsort()\n",
    "            self.im_files = [self.im_files[i] for i in irect]\n",
    "            self.shapes = s[irect]  # wh\n",
    "            ar = ar[irect]\n",
    "\n",
    "            # Set training image shapes\n",
    "            shapes = [[1, 1]] * nb\n",
    "            for i in range(nb):\n",
    "                ari = ar[bi == i]\n",
    "                mini, maxi = ari.min(), ari.max()\n",
    "                if maxi < 1:\n",
    "                    shapes[i] = [maxi, 1]\n",
    "                elif mini > 1:\n",
    "                    shapes[i] = [1, 1 / mini]\n",
    "\n",
    "            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(int) * stride\n",
    "            # print(self.batch_shapes)\n",
    "\n",
    "            \n",
    "    def get_img_cropped(self, center_x, center_y, width, height, img):\n",
    "        x1 = int(center_x - width // 2)\n",
    "        y1 = int(center_y - height // 2)\n",
    "        \n",
    "        x2 = int(x1 + width)\n",
    "        y2 = int(y1 + height)\n",
    "\n",
    "        cropped_image = img[y1:y2, x1:x2]\n",
    "        return cropped_image\n",
    "    \n",
    "    def load_image(self, i):\n",
    "        im, f = self.ims[i], self.im_files[i]\n",
    "        if im is None:  # not cached in RAM\n",
    "            im = cv2.imread(f)  # BGR\n",
    "            assert im is not None, f'Image Not Found {f}'\n",
    "            h0, w0 = im.shape[:2]  # orig hw\n",
    "            r = self.img_size / max(h0, w0)  # ratio\n",
    "            if r != 1:  # if sizes are not equal\n",
    "                interp = cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA\n",
    "                im = cv2.resize(im, (math.ceil(w0 * r), math.ceil(h0 * r)), interpolation=interp)\n",
    "            return im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized\n",
    "        return self.ims[i], self.im_hw0[i], self.im_hw[i]  # im, hw_original, hw_resized\n",
    "    \n",
    "    def get_labels(self, main_image, template):\n",
    "        main_gray = cv2.cvtColor(main_image, cv2.COLOR_BGR2GRAY)\n",
    "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "        template_width, template_height = template_gray.shape[::-1]\n",
    "\n",
    "\n",
    "        result = cv2.matchTemplate(main_gray, template_gray, cv2.TM_CCORR_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + template_width, top_left[1] + template_height)\n",
    "\n",
    "        center_x = (bottom_right[0] + top_left[0]) // 2\n",
    "        center_y = (bottom_right[1] + top_left[1]) // 2\n",
    "\n",
    "        center_point = (center_x, center_y)\n",
    "\n",
    "        h = bottom_right[1] - top_left[1]\n",
    "        w = bottom_right[0] - top_left[0]\n",
    "        \n",
    "        H, W, C = main_image.shape\n",
    "        img_size_scale = max(H, W)\n",
    "        # row = np.array([[0.0, \n",
    "        #                  center_x, \n",
    "        #                  center_y, \n",
    "        #                  w, \n",
    "        #                  h]])\n",
    "\n",
    "        # [bottom_right, top_left]\n",
    "\n",
    "        return np.array([[0.0, center_x, center_y, w, h]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        index_list = [i for i in range(0, len(self.im_files))]\n",
    "        index_list.remove(index)\n",
    "        rand_idx = random.choice(index_list)\n",
    "\n",
    "        index = self.indices[index]  # linear, shuffled, or image_weights\n",
    "        index1 = self.indices[rand_idx]  # linear, shuffled, or image_weights\n",
    "        \n",
    "        hyp = self.hyp\n",
    "\n",
    "        combined_image = np.zeros((self.img_size, self.img_size, 3))\n",
    "        combo_shapes = None\n",
    "\n",
    "        # Load image\n",
    "        img, (h0, w0), (h, w) = self.load_image(index)\n",
    "        img1, (h01, w01), (h1, w1) = self.load_image(index1)\n",
    "        # H, W, C = img.shape\n",
    "        # max_img_size = max(H,W)\n",
    "\n",
    "        # Letterbox\n",
    "        shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape\n",
    "        img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)\n",
    "        shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling\n",
    "\n",
    "\n",
    "        shape1 = self.batch_shapes[self.batch[index1]] if self.rect else self.img_size  # final letterboxed shape\n",
    "        img1, ratio1, pad1 = letterbox(img1, shape1, auto=False, scaleup=self.augment)\n",
    "        shapes1 = (h01, w01), ((h1 / h01, w1 / w01), pad1)  # for COCO mAP rescaling\n",
    "        \n",
    "\n",
    "        # labels = self.labels[index].copy()\n",
    "        # labels1 = self.labels[index1].copy()\n",
    "        labels = self.get_labels(img, self.template)\n",
    "        labels1 = self.get_labels(img1, self.template)\n",
    "        \n",
    "        \n",
    "        # print(\"=-----------------------\")\n",
    "        # print(labels1[0][1:]*img.shape[0])\n",
    "        center_x, center_y, width, height = labels[0][1:]\n",
    "        center_x1, center_y1, width1, height1 = labels1[0][1:]\n",
    "        # print(center_x1, center_y1, width1, height1)\n",
    "        # print(int(center_x1), int(center_y1), int(width1), int(height1))\n",
    "        cropped_img = self.get_img_cropped(center_x, center_y, width, height, img)\n",
    "        cropped_img1 = self.get_img_cropped(center_x1, center_y1, width1, height1, img1)\n",
    "        \n",
    "        # return [cropped_img, cropped_img1]\n",
    "        new_width = 100\n",
    "        new_height = 100\n",
    "        resized_image1 = cv2.resize(cropped_img, (new_width, new_height))\n",
    "        resized_image2 = cv2.resize(cropped_img1, (new_width, new_height))\n",
    "\n",
    "        ht, wd = img.shape[:2]\n",
    "        max_img_size = max(ht, wd)\n",
    "        combined_image = np.ones((ht, wd, 3), dtype=np.uint8) * 255\n",
    "\n",
    "        paste_x1 = random.randint(0, wd - new_width)\n",
    "        paste_y1 = random.randint(0, ht - new_height)\n",
    "        paste_x2 = random.randint(0, wd - new_width)\n",
    "        paste_y2 = random.randint(0, ht - new_height)\n",
    "\n",
    "        combined_image[paste_y1:paste_y1+new_height, paste_x1:paste_x1+new_width] = resized_image1\n",
    "        combined_image[paste_y2:paste_y2+new_height, paste_x2:paste_x2+new_width] = resized_image2\n",
    "\n",
    "        bottom_right = (paste_x1, paste_y1)\n",
    "        top_left = (paste_x1+new_width, paste_y1+new_height)\n",
    "\n",
    "        center_x = (bottom_right[0] + top_left[0]) // 2\n",
    "        center_y = (bottom_right[1] + top_left[1]) // 2\n",
    "        \n",
    "\n",
    "        \n",
    "        # center_point = (center_x, center_y)\n",
    "\n",
    "\n",
    "        bottom_right1 = (paste_x2, paste_y2)\n",
    "        top_left1 = (paste_x2+new_width, paste_y2+new_height)\n",
    "\n",
    "        center_x1 = (bottom_right1[0] + top_left1[0]) // 2\n",
    "        center_y1 = (bottom_right1[1] + top_left1[1]) // 2\n",
    "\n",
    "\n",
    "        # center_point1 = (center_x1, center_y1)\n",
    "        \n",
    "        # labels = (center_x, center_y, new_width, new_height)\n",
    "        # labels1 = (center_x1, center_y1, new_width, new_height)\n",
    "        \n",
    "        self.labels = np.array([[labels[0][0], center_x, center_y, new_width, new_height],\n",
    "                        [labels1[0][0], center_x1, center_y1, new_width, new_height]])/max_img_size\n",
    "        self.labels = self.labels.tolist()\n",
    "\n",
    "        \n",
    "        labels_main = np.array([[labels[0][0], center_x, center_y, new_width, new_height],\n",
    "                            [labels1[0][0], center_x1, center_y1, new_width, new_height]])/max_img_size\n",
    "        \n",
    "        \n",
    "        combo_shape = self.img_size  # final letterboxed shape\n",
    "        combined_image, combo_ratio, combo_pad = letterbox(combined_image, combo_shape, auto=False, scaleup=self.augment)\n",
    "        combo_shapes = (h01, w01), ((h1 / h01, w1 / w01), combo_pad)  # for COCO mAP rescaling\n",
    "        combined_image = combined_image.astype(np.uint8)\n",
    "\n",
    "        if labels_main.size:# and labels1.size:  # normalized xywh to pixel xyxy format\n",
    "            labels_main[:, 1:] = xywhn2xyxy(labels_main[:, 1:], combo_ratio[0] * w, combo_ratio[1] * h, padw=combo_pad[0], padh=combo_pad[1])\n",
    "            # labels1[:, 1:] = xywhn2xyxy(labels1[:, 1:], ratio1[0] * w1, ratio1[1] * h1, padw=pad1[0], padh=pad1[1])\n",
    "            # print(labels_main)\n",
    "        \n",
    "        if self.augment:\n",
    "            combined_image, labels_main = random_perspective(combined_image,\n",
    "                                            labels_main,\n",
    "                                            degrees=hyp['degrees'],\n",
    "                                            translate=hyp['translate'],\n",
    "                                            scale=hyp['scale'],\n",
    "                                            shear=hyp['shear'],\n",
    "                                            perspective=hyp['perspective'])\n",
    "\n",
    "        # print(\"*******************************\")\n",
    "        # print(combined_image)\n",
    "        nl = len(labels_main)  # number of labels_main\n",
    "        # nl1 = len(labels1)  # number of labels_main\n",
    "        if nl:# and nl1:\n",
    "            labels_main[:, 1:5] = xyxy2xywhn(labels_main[:, 1:5], w=combined_image.shape[1], h=combined_image.shape[0], clip=True, eps=1E-3)\n",
    "            # print(labels_main)\n",
    "        \n",
    "        # if self.augment:\n",
    "        #     # Albumentations\n",
    "        #     img, labels = self.albumentations(img, labels)\n",
    "        #     nl = len(labels)  # update after albumentations\n",
    "\n",
    "        #     # HSV color-space\n",
    "        #     augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])\n",
    "\n",
    "        #     # Flip up-down\n",
    "        #     if random.random() < hyp['flipud']:\n",
    "        #         img = np.flipud(img)\n",
    "        #         if nl:\n",
    "        #             labels[:, 2] = 1 - labels[:, 2]\n",
    "\n",
    "        #     # Flip left-right\n",
    "        #     if random.random() < hyp['fliplr']:\n",
    "        #         img = np.fliplr(img)\n",
    "        #         if nl:\n",
    "        #             labels[:, 1] = 1 - labels[:, 1]\n",
    "\n",
    "        #     # Cutouts\n",
    "        #     # labels = cutout(img, labels, p=0.5)\n",
    "        #     # nl = len(labels)  # update after cutout\n",
    "\n",
    "\n",
    "        labels_out = torch.zeros((nl, 6))\n",
    "        # labels_out1 = torch.zeros((nl1, 6))\n",
    "        if nl:# and nl1:\n",
    "            labels_out[:, 1:] = torch.from_numpy(labels_main)\n",
    "            # labels_out1[:, 1:] = torch.from_numpy(labels1)\n",
    "\n",
    "        # Convert\n",
    "        combined_image = combined_image.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n",
    "        combined_image = np.ascontiguousarray(combined_image)\n",
    "\n",
    "        return torch.from_numpy(combined_image), labels_out, self.im_files[index], combo_shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_custom = CustomDataset(\"/home/somusan/somusan/soumyadip/interview/lens_assignment/finger_data/images/train/\",img_size=640,batch_size=2, rect=True)\n",
    "dataloader_data = dataset_custom[3]\n",
    "dataloader_img = dataloader_data[0].permute(1,2,0).numpy()\n",
    "dataloader_labels = dataloader_data[1]\n",
    "print(dataloader_data[1])\n",
    "plt.imshow(dataloader_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
